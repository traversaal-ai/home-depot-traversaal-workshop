{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Exercise 2: Delivery Risk Assessment with External AI Models\n\nIn the previous exercise, we collected comprehensive delivery data by orchestrating multiple agents. Now we'll take that data and perform sophisticated risk assessment.\n\n## The Big Picture: Building Toward Intelligent Case Cards\n\nWe're building a complete **Delivery Intelligence System** that helps prevent delivery failures. Here's how this exercise fits in:\n\n```\n1. Data Collection (Exercise 1) → collected_order_data.json\n   ↓\n2. Risk Assessment (THIS EXERCISE) → risk_assessment_output.json\n   ↓\n3. Product Intelligence (Exercise 3) → product_analysis.json\n   ↓\n4. Communication & Cases (Exercise 4) → final_case_card.json\n```\n\n### What We'll Build in This Exercise\n\n1. **External AI Model Integration** - Calling a risk assessment model (simulating your proprietary model)\n2. **Multi-Factor Risk Analysis** - Weather, customer, and route risk factors\n3. **MCP Integration** - Using real weather data via Model Context Protocol\n4. **Risk Aggregation** - Combining all assessments into structured insights\n\n### The Final Goal\n\nBy the end of all exercises, we'll produce intelligent case cards that GOAs can use to:\n- Identify high-risk deliveries before they fail\n- Send pre-drafted, policy-compliant messages to customers\n- Communicate specific requirements to carriers\n- Suggest alternative delivery solutions\n\nThis exercise provides the **risk intelligence** that drives prioritization and recommendations."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "We'll set up the environment and import necessary libraries, including Vertex AI for model integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# Configure environment\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"traversaal-research\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "\n",
    "print(\"✅ Environment configured for risk assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Understanding the Data Flow\n\nIn this exercise, we'll use the actual data collected from Exercise 1. The data collection pipeline saves its output to `collected_order_data.json`, which we'll load and use for risk assessment.\n\nThis creates a realistic data pipeline where:\n- Exercise 1 collects data from BigQuery → `collected_order_data.json`\n- Exercise 2 loads that data and performs risk assessment → `risk_assessment_output.json`\n- Exercise 3 will use both outputs for product intelligence\n- Exercise 4 will combine everything for communication generation\n\nLet's load the data from Exercise 1:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Load the order data from Exercise 1\ndef load_order_data(file_path: str = '../exercise_1_data_collection/collected_order_data.json'):\n    \"\"\"Load order data from Exercise 1 output\"\"\"\n    try:\n        with open(file_path, 'r') as f:\n            return json.load(f)\n    except FileNotFoundError:\n        print(f\"⚠️ Warning: {file_path} not found.\")\n        print(\"Please run Exercise 1 first to generate the data.\")\n        print(\"Using fallback sample data for demonstration...\")\n        \n        # Fallback data if Exercise 1 hasn't been run\n        return {\n            \"order\": {\n                \"DATA_ID\": 2204,\n                \"CUSTOMER_ORDER_NUMBER\": \"CG92094171\",\n                \"SCHEDULED_DELIVERY_DATE\": \"2025-06-21T00:00:00\",\n                \"VEHICLE_TYPE\": \"FLAT\",\n                \"QUANTITY\": 109,\n                \"VOLUME_CUBEFT\": 34.9,\n                \"WEIGHT\": 1598,\n                \"PALLET\": 3,\n                \"WINDOW_START\": \"06:00:00\",\n                \"WINDOW_END\": \"20:00:00\"\n            },\n            \"customer\": {\n                \"CUSTOMER_NAME\": \"CUST_01518\",\n                \"PRO_XTRA_MEMBER\": True,\n                \"COMMERCIAL_ADDRESS_FLAG\": False,\n                \"DESTINATION_ADDRESS\": \"668 FOREST AVE ELGIN, IL 60120\",\n                \"CUSTOMER_NOTES\": \"call b/4 delivery delivery from the back of the building\"\n            },\n            \"products\": [\n                \"2 in. x 12 in. x 8 ft. 2 Prime Ground Contact Pressure-Treated Lumber\",\n                \"2 in. x 4 in. x 12 ft. 2 Prime Ground Contact Pressure-Treated Southern Yellow Pine Lumber\"\n            ],\n            \"environmental\": {\n                \"WTHR_CATEGORY\": \"Clear\",\n                \"PRECIPITATION\": \"0.09 inch\",\n                \"STRT_VW_IMG_DSCRPTN\": \"* The driveway is partially obscured by trees\"\n            },\n            \"risk_info\": {\n                \"DLVRY_RISK_DECILE\": 6,\n                \"DLVRY_RISK_BUCKET\": \"MEDIUM\",\n                \"DLVRY_RISK_PERCENTILE\": 40,\n                \"DLVRY_RISK_TOP_FEATURE\": \"WORK_ORD_TOTAL,LUMBER_CNT,IS_SPECIFIC_DLVRY_WINDOW\"\n            }\n        }\n\n# Load the actual order data\norder_data = load_order_data()\n\nprint(\"📦 Order Summary:\")\nprint(f\"  - Order #: {order_data['order']['CUSTOMER_ORDER_NUMBER']}\")\nprint(f\"  - Weight: {order_data['order']['WEIGHT']} lbs\")\nprint(f\"  - Products: {len(order_data['products'])} items\")\nprint(f\"  - Customer: PRO Member = {order_data['customer']['PRO_XTRA_MEMBER']}\")\nprint(f\"  - Risk Level (Pre-calculated): {order_data.get('risk_info', {}).get('DLVRY_RISK_BUCKET', 'Unknown')}\")\n\n# Display customer notes if present\ncustomer_notes = order_data['customer'].get('CUSTOMER_NOTES')\nif customer_notes:\n    print(f\"  - Special Instructions: {customer_notes}\")\nelse:\n    print(\"  - Special Instructions: None\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating External AI Models\n",
    "\n",
    "One of ADK's strengths is integrating with existing AI models. Your organization likely has proprietary risk models that you want to keep using.\n",
    "\n",
    "Here we'll create a tool that:\n",
    "1. Calls an external AI model (we'll use Gemini to simulate your model)\n",
    "2. Returns risk assessments in **your exact format**\n",
    "3. Can easily be swapped with your actual model endpoint\n",
    "\n",
    "The model returns:\n",
    "- `DLVRY_RISK_DECILE`: 1-10 scale (10 = highest risk)\n",
    "- `DLVRY_RISK_BUCKET`: HIGH/MEDIUM/LOW categorization\n",
    "- `DLVRY_RISK_PERCENTILE`: 0-100 percentile ranking\n",
    "- `DLVRY_RISK_TOP_FEATURE`: Key risk factors identified"
   ]
  },
  {
   "cell_type": "code",
   "source": "# First, let's see the structure of a simple MCP server for weather\n# In production, you'd have this as a separate service\n\nweather_mcp_server_code = '''#!/usr/bin/env python3\n\"\"\"\nSimple Weather MCP Server - Demonstrates MCP integration for ADK\n\nThis server provides:\n1. get_weather - Get weather for a city/date\n2. assess_weather_risk - Assess delivery risk based on weather\n\"\"\"\n\nfrom mcp.server import Server, NotificationOptions\nfrom mcp.server.models import InitializationOptions\nfrom mcp.server.stdio import stdio_server\nfrom mcp import types\nimport json\nimport asyncio\n\napp = Server(\"weather-server\")\n\n# For demo: simulated weather data\nDEMO_WEATHER_DATA = {\n    \"chicago\": {\n        \"temperature\": 72,\n        \"conditions\": \"Partly Cloudy\",\n        \"precipitation\": 0.0,\n        \"wind_speed\": 8,\n        \"humidity\": 65\n    },\n    \"new york\": {\n        \"temperature\": 68,\n        \"conditions\": \"Clear\",\n        \"precipitation\": 0.0,\n        \"wind_speed\": 5,\n        \"humidity\": 55\n    }\n}\n\n@app.list_tools()\nasync def list_tools() -> list[types.Tool]:\n    \"\"\"List available weather tools\"\"\"\n    return [\n        types.Tool(\n            name=\"assess_weather_risk\",\n            description=\"Assess delivery risk based on weather conditions\",\n            inputSchema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"city\": {\"type\": \"string\", \"description\": \"City name\"},\n                    \"date\": {\"type\": \"string\", \"description\": \"Delivery date\"}\n                },\n                \"required\": [\"city\", \"date\"]\n            }\n        )\n    ]\n\n@app.call_tool()\nasync def call_tool(name: str, arguments: Any) -> list[types.TextContent]:\n    \"\"\"Handle tool calls\"\"\"\n    if name == \"assess_weather_risk\":\n        city = arguments.get(\"city\", \"\").lower()\n        weather = DEMO_WEATHER_DATA.get(city, DEMO_WEATHER_DATA[\"chicago\"])\n        \n        # Risk assessment logic\n        risk_score = 1\n        risk_factors = []\n        \n        if weather[\"precipitation\"] > 0.5:\n            risk_score = 6\n            risk_factors.append(\"Precipitation\")\n        elif \"storm\" in weather[\"conditions\"].lower():\n            risk_score = 8\n            risk_factors.append(\"Storm conditions\")\n        else:\n            risk_factors.append(\"Favorable weather\")\n            \n        return [types.TextContent(\n            type=\"text\",\n            text=json.dumps({\n                \"weather_risk_score\": risk_score,\n                \"weather_factors\": risk_factors,\n                \"weather_data\": weather,\n                \"risk_level\": \"HIGH\" if risk_score >= 7 else \"MEDIUM\" if risk_score >= 4 else \"LOW\"\n            }, indent=2)\n        )]\n'''\n\n# Save the server code for reference\nwith open('weather_mcp_server_demo.py', 'w') as f:\n    f.write(weather_mcp_server_code)\n\nprint(\"✅ Weather MCP Server example created\")\nprint(\"\\nKey MCP concepts demonstrated:\")\nprint(\"1. Server definition with app = Server()\")\nprint(\"2. Tool listing with @app.list_tools()\")\nprint(\"3. Tool execution with @app.call_tool()\")\nprint(\"4. Structured input/output schemas\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Model Context Protocol (MCP) Integration\n\nBefore we look at the external model integration, let's explore a powerful ADK feature: **Model Context Protocol (MCP)**.\n\n### What is MCP?\n\nMCP is an open standard that allows LLMs to communicate with external applications and services through a standardized protocol. Think of it as a universal adapter that lets your agents connect to any service that speaks MCP.\n\n### Why use MCP in our Risk Assessment?\n\nIn our current implementation, we use mock weather data. But in production, you'd want **real weather forecasts** for the delivery date. MCP allows us to:\n\n1. **Connect to external services** without writing custom integration code\n2. **Use community-built MCP servers** or create our own\n3. **Maintain clean separation** between our agent logic and external services\n4. **Easily swap services** without changing agent code\n\nLet's create a simple weather MCP server that our risk assessment can use!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "from typing import Dict, Any\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\nimport google.auth\n\n# Initialize Vertex AI\ncredentials, project = google.auth.default()\nvertexai.init(project=project, location=\"us-central1\")\n\ndef call_external_risk_model(order_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Call external risk assessment model.\n    In production, this would call the client's proprietary model.\n    For the workshop, we'll use the pre-calculated risk data from BigQuery.\n    \"\"\"\n    # Extract pre-calculated risk info from the order data\n    risk_info = order_data.get('risk_info', {})\n    \n    # Map the BigQuery risk data to the expected format\n    risk_bucket = risk_info.get('DLVRY_RISK_BUCKET', 'MEDIUM')\n    risk_decile = risk_info.get('DLVRY_RISK_DECILE', 5)\n    risk_percentile = risk_info.get('DLVRY_RISK_PERCENTILE', 50)\n    top_features = risk_info.get('DLVRY_RISK_TOP_FEATURE', '').split(',')\n    \n    # Return in the format expected by the pipeline\n    return {\n        \"status\": \"success\",\n        \"risk_assessment\": {\n            \"overall_risk_score\": risk_decile,\n            \"risk_level\": risk_bucket,\n            \"risk_percentile\": risk_percentile,\n            \"top_risk_factors\": top_features,\n            \"model_version\": \"bigquery_precalculated_v1\"\n        }\n    }\n\nprint(\"✅ External model integration configured\")\nprint(\"💡 Using pre-calculated risk scores from BigQuery data\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Risk Assessment Tools\n",
    "\n",
    "While your external model provides the primary risk assessment, we can enhance it with specific risk factors. These additional assessments can:\n",
    "- Provide more granular insights\n",
    "- Validate the external model's assessment\n",
    "- Identify risks the general model might miss\n",
    "\n",
    "Let's create specialized risk assessment tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "def assess_weather_risk(environmental_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Assess weather-related delivery risks\"\"\"\n    precipitation = environmental_data.get('PRECIPITATION', 0)\n    weather_category = environmental_data.get('WTHR_CATEGORY', 'Unknown')\n    \n    # Simple weather risk scoring\n    risk_score = 0\n    factors = []\n    \n    # Handle precipitation as string (e.g., \"0.09 inch\")\n    if isinstance(precipitation, str):\n        precipitation = float(precipitation.replace(' inch', ''))\n    \n    if precipitation > 0.5:\n        risk_score = 8\n        factors.append(f\"Heavy precipitation ({precipitation} inches)\")\n    elif precipitation > 0.1:\n        risk_score = 4\n        factors.append(f\"Light precipitation ({precipitation} inches)\")\n    else:\n        risk_score = 2\n        factors.append(\"Favorable weather\")\n    \n    if weather_category.lower() in ['rain', 'snow', 'storm']:\n        risk_score = min(10, risk_score + 3)\n        factors.append(f\"Adverse weather: {weather_category}\")\n    \n    return {\n        \"weather_risk_score\": risk_score,\n        \"weather_factors\": factors,\n        \"precipitation_inches\": precipitation,\n        \"category\": weather_category\n    }\n\n\ndef assess_customer_risk(customer_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Assess customer-related delivery risks\"\"\"\n    risk_score = 5  # Base score\n    factors = []\n    \n    # PRO customers typically have lower risk\n    if customer_data.get('PRO_XTRA_MEMBER', False):\n        risk_score -= 2\n        factors.append(\"PRO customer (lower risk)\")\n    \n    # Commercial vs residential\n    if customer_data.get('COMMERCIAL_ADDRESS_FLAG', False):\n        risk_score -= 1\n        factors.append(\"Commercial address\")\n    else:\n        risk_score += 2\n        factors.append(\"Residential address\")\n    \n    # Customer notes indicate special requirements\n    if customer_data.get('CUSTOMER_NOTES'):\n        risk_score += 2\n        factors.append(\"Special delivery instructions\")\n        \n    return {\n        \"customer_risk_score\": max(1, min(10, risk_score)),\n        \"customer_factors\": factors,\n        \"has_special_instructions\": bool(customer_data.get('CUSTOMER_NOTES'))\n    }\n\n\ndef assess_route_risk(order_data: Dict[str, Any], environmental_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Assess route and accessibility risks\"\"\"\n    risk_score = 5  # Base score\n    factors = []\n    \n    # Vehicle type considerations\n    vehicle_type = order_data.get('VEHICLE_TYPE', 'UNKNOWN')\n    if vehicle_type == 'FLAT' and order_data.get('WEIGHT', 0) > 1000:\n        risk_score += 2\n        factors.append(\"Heavy load on flatbed\")\n    \n    # Street view analysis\n    street_desc = environmental_data.get('STRT_VW_IMG_DSCRPTN', '')\n    if 'dead end' in street_desc.lower():\n        risk_score += 2\n        factors.append(\"Dead end street\")\n    if 'limited' in street_desc.lower() or 'narrow' in street_desc.lower():\n        risk_score += 1\n        factors.append(\"Access limitations noted\")\n    \n    return {\n        \"route_risk_score\": max(1, min(10, risk_score)),\n        \"route_factors\": factors,\n        \"access_notes\": street_desc\n    }\n\nprint(\"✅ Risk assessment tools created\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Building the Risk Assessment Pipeline\n\nNow let's create agents that use these tools and orchestrate them into a complete risk assessment pipeline:\n\n1. **External Risk Agent**: Calls your proprietary model (simulated with pre-calculated BigQuery data)\n2. **Weather Risk Agent**: Uses MCP to get weather risk assessment from our weather service!\n3. **Customer Risk Agent**: Assesses customer-specific risks\n4. **Route Risk Agent**: Assesses route and accessibility risks\n\n### MCP Integration for Weather\n\nThe weather agent now uses `MCPToolset` to connect to our weather MCP server. This demonstrates how easily you can integrate external services into your ADK agents:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, StdioServerParameters\nimport sys\n\nGEMINI_MODEL = \"gemini-2.0-flash\"\n\n# Agent that calls your external risk model\nexternal_risk_agent = Agent(\n    model=GEMINI_MODEL,\n    name=\"external_risk_agent\",\n    description=\"Integrates with external risk assessment model\",\n    instruction=\"\"\"\\\nYou will receive consolidated order data in the user message.\nParse the JSON order data from the user message and use the call_external_risk_model tool to get risk assessment from the external model.\nPass the entire order data structure to the model and return its assessment.\nThis demonstrates integration with external AI models - in production, this would call the client's proprietary risk model.\n\"\"\",\n    tools=[call_external_risk_model],\n    output_key=\"external_risk_assessment\"\n)\n\n# Weather risk agent - NOW WITH MCP INTEGRATION!\nweather_risk_agent = Agent(\n    model=GEMINI_MODEL,\n    name=\"weather_risk_agent\",\n    description=\"Assesses weather-related delivery risks using MCP weather service\",\n    instruction=\"\"\"\\\nYou will receive order data in the user message.\n\nParse the JSON order data and:\n1. Extract the delivery date from order.SCHEDULED_DELIVERY_DATE (format: \"2025-06-21T00:00:00\")\n2. Extract the city - for Chicago area deliveries, use \"Chicago\"\n3. Use the 'assess_weather_risk' MCP tool with the city and date\n\nThe tool will return structured risk data including:\n- weather_risk_score (1-10)\n- weather_factors (list of risk factors)\n- weather_data (temperature, conditions, precipitation, etc.)\n- risk_level (HIGH/MEDIUM/LOW)\n\nReturn the complete response from the MCP tool.\n\"\"\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioServerParameters(\n                # Use Python to run the weather MCP server\n                command=sys.executable,\n                args=[os.path.abspath(\"./weather_mcp_server.py\")],\n            ),\n            # Filter to only expose the risk assessment tool\n            tool_filter=['assess_weather_risk']\n        )\n    ],\n    output_key=\"weather_risk\"\n)\n\n# Customer risk agent  \ncustomer_risk_agent = Agent(\n    model=GEMINI_MODEL,\n    name=\"customer_risk_agent\",\n    description=\"Assesses customer-related delivery risks\",\n    instruction=\"\"\"\\\nYou will receive order data in the user message.\nParse the JSON order data, extract the customer data and use the assess_customer_risk tool to evaluate customer-related delivery risks.\nConsider PRO status, special instructions, and address type.\n\"\"\",\n    tools=[assess_customer_risk],\n    output_key=\"customer_risk\"\n)\n\n# Route risk agent\nroute_risk_agent = Agent(\n    model=GEMINI_MODEL,\n    name=\"route_risk_agent\",\n    description=\"Assesses route and accessibility risks\",\n    instruction=\"\"\"\\\nYou will receive order data in the user message.\nParse the JSON order data, extract order and environmental data, then use the assess_route_risk tool to evaluate route-related delivery risks.\nConsider load weight, vehicle requirements, and street accessibility.\n\"\"\",\n    tools=[assess_route_risk],\n    output_key=\"route_risk\"\n)\n\nprint(\"✅ Risk assessment agents created\")\nprint(\"\\n🔍 Key MCP Integration Points:\")\nprint(\"1. MCPToolset wraps the MCP connection\")\nprint(\"2. StdioServerParameters defines how to connect (command + args)\")\nprint(\"3. tool_filter lets you select specific tools from the MCP server\")\nprint(\"4. The agent uses MCP tools just like regular ADK tools!\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Orchestrating Risk Assessments\n\nWe'll run the additional risk assessments in parallel for efficiency:"
  },
  {
   "cell_type": "code",
   "source": "# Parallel execution of additional risk assessments\nadditional_risks_agent = ParallelAgent(\n    name=\"additional_risks_agent\",\n    sub_agents=[weather_risk_agent, customer_risk_agent, route_risk_agent],\n    description=\"Assess multiple risk factors in parallel\"\n)\n\nprint(\"✅ Parallel risk assessments configured\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Final risk aggregation agent - outputs structured JSON\nrisk_aggregation_agent = Agent(\n    name=\"risk_aggregation_agent\",\n    model=GEMINI_MODEL,\n    description=\"Aggregates all risk assessments into structured output\",\n    instruction=\"\"\"\\\nYou have received multiple risk assessments:\n\nExternal Model Assessment: {external_risk_assessment}\nWeather Risk: {weather_risk}\nCustomer Risk: {customer_risk}\nRoute Risk: {route_risk}\n\nCreate a structured JSON output that includes:\n\n{\n    \"risk_assessment\": {\n        \"overall_risk_score\": <external model decile>,\n        \"risk_level\": \"<HIGH/MEDIUM/LOW from external model>\",\n        \"risk_percentile\": <external model percentile>,\n        \"risk_scores\": {\n            \"overall\": <external model decile>,\n            \"weather\": <weather_risk_score>,\n            \"customer\": <customer_risk_score>,\n            \"route\": <route_risk_score>\n        },\n        \"risk_factors\": [\n            // Array of all identified risk factors from all assessments\n        ],\n        \"top_risks\": \"<external model top features>\",\n        \"recommendations\": [\n            {\n                \"action\": \"<specific action>\",\n                \"priority\": \"<HIGH/MEDIUM/LOW>\",\n                \"reason\": \"<why this is needed>\"\n            }\n        ],\n        \"weather_data\": {\n            // Include weather assessment details\n        }\n    }\n}\n\nReturn ONLY the JSON structure, no additional text or markdown.\n\"\"\",\n    tools=[],\n    output_key=\"risk_assessment_data\"\n)\n\nprint(\"✅ Risk aggregation agent created\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Building the Complete Pipeline\n\nNow let's assemble all the agents into a sequential pipeline:"
  },
  {
   "cell_type": "code",
   "source": "# Full risk assessment pipeline\nrisk_assessment_pipeline = SequentialAgent(\n    name=\"risk_assessment_pipeline\",\n    sub_agents=[external_risk_agent, additional_risks_agent, risk_aggregation_agent],\n    description=\"Complete risk assessment pipeline with external model integration and real weather data\"\n)\n\nprint(\"✅ Risk assessment pipeline assembled\")\nprint(\"\\nPipeline flow:\")\nprint(\"1️⃣  External Risk Model\")\nprint(\"2️⃣  Parallel: Weather + Customer + Route Analysis\")  \nprint(\"3️⃣  Risk Aggregation → Structured JSON Output\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Running the Complete Risk Assessment\n\nNow let's run the pipeline with our actual order data from Exercise 1:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Run the risk assessment pipeline\nimport asyncio\nimport sys\nimport io\n\nasync def run_risk_assessment_demo():\n    \"\"\"Run risk assessment pipeline on the loaded order data\"\"\"\n    \n    # Setup\n    session_service = InMemorySessionService()\n    await session_service.create_session(\n        app_name=\"risk_assessment\",\n        user_id=\"user_1\",\n        session_id=\"risk_session_001\"\n    )\n    \n    runner = Runner(\n        agent=risk_assessment_pipeline,\n        app_name=\"risk_assessment\",\n        session_service=session_service\n    )\n    \n    print(\"=\" * 60)\n    print(\"DELIVERY RISK ASSESSMENT PIPELINE\")\n    print(\"=\" * 60)\n    print(f\"\\nAssessing risk for order: {order_data.get('order', {}).get('CUSTOMER_ORDER_NUMBER', 'Unknown')}\")\n    print(f\"Customer: {order_data.get('customer', {}).get('CUSTOMER_NAME', 'Unknown')}\")\n    print(f\"Risk Level (Pre-calculated): {order_data.get('risk_info', {}).get('DLVRY_RISK_BUCKET', 'Unknown')}\")\n    print(\"\\nRunning comprehensive risk assessment...\\n\")\n    \n    # Create message\n    content = types.Content(\n        role=\"user\",\n        parts=[types.Part(text=json.dumps(order_data))]\n    )\n    \n    # Run pipeline with output suppression\n    old_stderr = sys.stderr\n    sys.stderr = io.StringIO()\n    \n    try:\n        async for event in runner.run_async(\n            user_id=\"user_1\",\n            session_id=\"risk_session_001\",\n            new_message=content\n        ):\n            sys.stderr = old_stderr\n            \n            if hasattr(event, \"author\") and event.author:\n                if event.author in [\"external_risk_agent\", \"weather_risk_agent\", \n                                  \"customer_risk_agent\", \"route_risk_agent\"]:\n                    print(f\"[{event.author}] analyzing...\")\n                    \n            if event.is_final_response() and event.author == \"risk_aggregation_agent\":\n                if event.content and event.content.parts:\n                    print(\"\\n\" + \"=\" * 60)\n                    print(\"RISK ASSESSMENT COMPLETE\")\n                    print(\"=\" * 60)\n                    \n                    # Parse and display JSON\n                    try:\n                        response_text = event.content.parts[0].text.strip()\n                        if response_text.startswith(\"```json\"):\n                            response_text = response_text[7:]\n                        if response_text.endswith(\"```\"):\n                            response_text = response_text[:-3]\n                        \n                        risk_data = json.loads(response_text.strip())\n                        \n                        # Save to file\n                        with open('risk_assessment_output.json', 'w') as f:\n                            json.dump(risk_data, f, indent=2)\n                        \n                        # Display key results\n                        assessment = risk_data.get('risk_assessment', {})\n                        print(f\"\\n📊 Overall Risk Score: {assessment.get('overall_risk_score')}/10\")\n                        print(f\"⚠️  Risk Level: {assessment.get('risk_level')}\")\n                        print(f\"📈 Risk Percentile: {assessment.get('risk_percentile')}%\")\n                        \n                        print(\"\\n🔍 Risk Scores by Category:\")\n                        scores = assessment.get('risk_scores', {})\n                        print(f\"   - Weather: {scores.get('weather')}/10\")\n                        print(f\"   - Customer: {scores.get('customer')}/10\")\n                        print(f\"   - Route: {scores.get('route')}/10\")\n                        \n                        print(\"\\n⚡ Top Risk Factors:\")\n                        for factor in assessment.get('risk_factors', [])[:5]:\n                            print(f\"   - {factor}\")\n                        \n                        print(\"\\n💡 Recommendations:\")\n                        for rec in assessment.get('recommendations', [])[:3]:\n                            print(f\"   - [{rec['priority']}] {rec['action']}\")\n                            print(f\"     Reason: {rec['reason']}\")\n                        \n                        print(\"\\n✅ Risk assessment saved to risk_assessment_output.json\")\n                        \n                        return risk_data\n                        \n                    except Exception as e:\n                        print(f\"Error parsing JSON: {e}\")\n                        print(event.content.parts[0].text)\n                break\n                \n            sys.stderr = io.StringIO()\n    finally:\n        sys.stderr = old_stderr\n\n# Run the demonstration\nresult = await run_risk_assessment_demo()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Understanding the MCP Output\n\nLet's examine what the weather MCP server returned:\n\n```json\n{\n  \"city\": \"Chicago\",\n  \"date\": \"2025-06-21\",\n  \"weather_risk_score\": 1,\n  \"weather_factors\": [\"Favorable weather conditions\"],\n  \"weather_data\": {\n    \"temperature\": 72,\n    \"conditions\": \"Partly Cloudy\",\n    \"precipitation\": 0.0,\n    \"wind_speed\": 8,\n    \"humidity\": 65\n  },\n  \"risk_level\": \"LOW\",\n  \"mode\": \"demo\"\n}\n```\n\nThe MCP server:\n1. Received the city and date from our weather agent\n2. Assessed the weather conditions (currently using demo data)\n3. Calculated a risk score based on precipitation, wind, and conditions\n4. Returned structured data that our pipeline can use\n\nIn production, you would:\n- Set `OPENWEATHER_API_KEY` environment variable for real weather data\n- Deploy the MCP server as a microservice\n- Use caching to reduce API calls\n- Add authentication for security",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Structured Output for Pipeline Integration\n\nThe risk assessment now outputs structured JSON data that includes:\n\n- **Risk Scores**: Overall and category-specific scores (1-10)\n- **Risk Level**: HIGH/MEDIUM/LOW classification\n- **Risk Factors**: Detailed list of identified risks\n- **Recommendations**: Actionable items with priorities\n- **Weather Data**: Real-time or simulated weather information\n\nThis structured output (`risk_assessment_output.json`) can be:\n1. Combined with order data from the previous pipeline\n2. Used to calculate priority scores\n3. Fed into communication generation systems\n4. Consumed by UI applications\n\nThe modular design ensures each pipeline stage produces reusable, structured data!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Key Takeaways\n\nThis exercise demonstrated several important patterns:\n\n### 1. **External Model Integration**\n- Easy to integrate existing AI models into ADK workflows\n- Used pre-calculated risk scores from BigQuery data\n- Simple to swap between different model providers\n\n### 2. **MCP (Model Context Protocol) Integration**\n- Connected to external weather service via MCP\n- Weather agent uses `MCPToolset` to call the weather risk assessment\n- MCP server provides standardized interface for external services\n- Easy to switch between demo mode and real weather APIs\n\n### 3. **Multi-Factor Risk Analysis**\n- Parallel agents assess different risk dimensions\n- Specialized tools for specific risk factors\n- Comprehensive view beyond single model assessment\n\n### 4. **Production Considerations**\n```python\n# Instead of our demo model:\nmodel = GenerativeModel(\"gemini-1.5-flash\")\n\n# You would use:\n# Option 1: Your proprietary model endpoint\nresponse = requests.post(\"https://your-model.api/assess\", json=order_data)\n\n# Option 2: Claude from Model Garden\nmodel = GenerativeModel(\"claude-3-sonnet@20240229\")\n\n# Option 3: Your custom Vertex AI model\nendpoint = aiplatform.Endpoint(\"your-endpoint-id\")\nresponse = endpoint.predict(instances=[order_data])\n```\n\n### 5. **Actionable Insights**\n- Not just risk scores, but specific recommendations\n- Comparison between models for validation\n- Clear prioritization of mitigation actions\n\n### 6. **Benefits of MCP**\n- **Standardized Interface**: All MCP servers follow the same protocol\n- **Language Agnostic**: Can use MCP servers written in any language\n- **Easy Integration**: MCPToolset makes it simple to add external services\n- **Flexibility**: Switch between local development and production services\n\n## Next Steps\n\nIn the next exercise, we'll take these risk assessments and:\n1. Analyze product characteristics for special handling needs\n2. Calculate priority scores based on multiple factors\n3. Generate intelligent insights for delivery optimization\n\nThe modular design means you can easily:\n- Replace the external model with your own\n- Add new risk factors\n- Customize the output format\n- Integrate with your existing systems\n- Switch MCP servers for different weather providers",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Important: Session State Setup\n\nNotice that we set the session state **before** creating the Runner. This is crucial because:\n\n1. The ADK framework attempts to substitute template variables (like `{order_data}`) when agents are initialized\n2. If the session state isn't populated yet, you'll get a `KeyError` about missing context variables\n3. By setting the state first, the agents can properly access the data during initialization\n\nIn the current implementation, we've also updated the agent instructions to parse data from the user message instead of relying solely on template substitution, making the system more robust.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}